import dotenv from 'dotenv'
import fs from 'fs'
import asyncFs from 'fs/promises'
import path from 'path'
import * as zx from 'zx'

export async function dbExecute(sql = '') {
  const { db } = await import('@/db')
  function execute() {
    if (typeof db.execute === 'function') {
      return db.execute.bind(db)
    }
    if (typeof db.$client.execute === 'function') {
      return db.$client.execute.bind(db.$client)
    }
    exitWithDbClose(1)
    throw new Error('æ— æ³•èŽ·å–æ•°æ®åº“ execute() æ–¹æ³•')
  }
  return execute()(sql)
}

export async function testDbConnect() {
  try {
    dbExecute('SELECT 1;')
    return true
  } catch (err) {
    console.error(err)
    return false
  }
}

// åŠ è½½çŽ¯å¢ƒå˜é‡
export async function loadEnv() {
  // å‘½ä»¤è¡Œä¼ å…¥ -P æˆ– --production å°†ä½¿ç”¨æ­£å¼çŽ¯å¢ƒå˜é‡
  const args = zx.minimist(process.argv.slice(2), { alias: { production: 'P' } })
  const isProduction = args.production === true
  if (!process.env.NODE_ENV) {
    // ä¸è€ƒè™‘ test çš„æƒ…å†µ
    process.env.NODE_ENV = isProduction ? 'production' : 'development'
  }
  const NextEnv = await import('@next/env')
  const loadEnvConfig = NextEnv.loadEnvConfig || NextEnv.default.loadEnvConfig
  loadEnvConfig(process.cwd(), isProduction)
  tryLoadParentGitRepoEnv()
}


// å½“å‰åº”ç”¨å¦‚æžœä½œä¸º git submodule å­˜åœ¨ï¼ŒåŠ è½½çˆ¶çº§ç›®å½•æ˜¯çš„çŽ¯å¢ƒé…ç½®æ–‡ä»¶
export function tryLoadParentGitRepoEnv() {
  if (!fs.existsSync(path.resolve('..', '.gitmodules'))) return
  const envPaths = [path.resolve('..', '.env'), path.resolve('..', '.env.' + process.env.NODE_ENV)]
  for (const envPath of envPaths) {
    if (!fs.existsSync(envPath)) continue
    dotenv.config({
      path: envPath,
      override: true,
    })
  }
  console.log(zx.chalk.cyan('ðŸ’¡ å½“å‰é¡¹ç›®ä½œä¸º git submoduleï¼Œå·²åŠ è½½ä¸»ç›®å½•çŽ¯å¢ƒé…ç½®'))
}


export function checkEnvs() {
  const requiredVariables = [
    'DB_DRIVER',
    'DB_CONNECTION_URL',
    'AUTH_SECRET',
  ]
  const unsetEnv = requiredVariables.filter((variable) => !process.env[variable])
  if (!process.env.AUTH_URL && process.env.VERCEL_URL) {
    process.env.AUTH_URL = process.env.VERCEL_URL
  }
  if (process.env.NODE_ENV === 'production' && !process.env.AUTH_URL) {
    unsetEnv.push('AUTH_URL')
  }
  if (unsetEnv.length) {
    zx.echo(zx.chalk.red('çŽ¯å¢ƒå˜é‡ç¼ºå¤±: ' + unsetEnv.join(', ') + '\n'))
    process.exit(1)
  }
  if (process.env.DB_DRIVER !== 'postgresql' && process.env.DB_DRIVER !== 'sqlite') {
    zx.echo(zx.chalk.red('DB_DRIVER åªèƒ½ä¸º postgresql æˆ– sqlite'))
    process.exit(1)
  }
}

export async function exitWithDbClose(code = 0) {
  const { db } = await import('@/db')
  if ('end' in db.$client) {
    await Promise.resolve(db.$client.end())
  } else if ('close' in db.$client) {
    await Promise.resolve(db.$client.close())
  }
  process.exit(code)
}


export async function declareLocalType() {
  if (!process.env.DB_DRIVER) throw new Error('çŽ¯å¢ƒå˜é‡ DB_DRIVER æœªå®šä¹‰')
  const targetPath = path.resolve('local.d.ts')
  const fileContent = `
declare global {
  type DB_DRIVER ='${process.env.DB_DRIVER}'
}
export {}
`.trim()
  try {
    // ä»…å½“å†…å®¹å˜åŒ–æ—¶æ‰å†™å…¥
    const existingContent = await asyncFs.readFile(targetPath, 'utf8').catch(() => '')
    if (existingContent.trim() === fileContent) return
    await asyncFs.writeFile(targetPath, fileContent, { encoding: 'utf-8' })
    console.log(`Type declaration updated at ${targetPath}`)
  } catch (error) {
    console.error('Failed to generate type declaration:', error)
    process.exit(1)
  }
}
